<!doctype html>
<!doctype html>
<html lang="en">

	<head>
		<meta charset="utf-8">
		
		<!-- BASE URL: change this href to the intended URL of your slide show, e.g. - http://USERNAME.github.io/SLIDESHOW-REPO/ -->
		<base href="http://millsjb.github.io/inls161-revealjs-template//"> 

		<title>In-Car UX</title>
		
		
		<meta name="author" content="Josh Mills">
		
		<meta name="apple-mobile-web-app-capable" content="yes" />
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
		
		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/night.css" id="theme">
		<!-- Code syntax highlighting -->
  		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>

		<!--[if lt IE 9]>
		<script src="lib/js/html5shiv.js"></script>
		<![endif]-->
	</head>

	<body>
		
		<div class="reveal">

			<!-- Any section element inside of this container is displayed as a slide -->
			<div class="slides">
				
				<section>
					<h2>In-Car UX</h2>
					<p>Josh Mills</p>
					<p>
						<h4>2016-01-28</h4>
					</p>
				</section>

<section class="slide level1">
<p>Research Area</p>
<aside class="notes">
•	The advent of ultra-high resolution wall-size displays and their use for complex tasks require a more systematic analysis 
and deeper understanding of their advantages and drawbacks compared with desktop monitors. 
</aside>
</section>

<section class="slide level1">
<p>Is past research on desktop-sized displays still relavent?</p>
<aside class="notes">
Wall-size displays are becoming more common and therefore raising the question as to whether existing research findings on 
desktop-size displays still apply to this new environment.
</aside>
</section>

<section class="slide level1">
<a href="#">
	<img src="http://www.scsc.no/daniel/img/comics.jpg" 
	alt="Ref image" style="width:80%;height:300px;">
</a>
<aside class="notes">
Wall-sized displays offer a unique experience with many advantages  
</aside>
</section>

<section class="slide level1">
<p>Advantages:</p>
	
	<section class="level1">
	<p>The size of the data-set is the primary reason users want to move off of a desktop</p>
	</section>
	
	<section class="level1">
	<p>Virtual navigation imposed by a desktop interface can be disorienting, and the overhead of constantly 
	navigating the data set, e.g. with pan-and-zoom, can distract users and increase their cognitive load. </p>
	</section>
	
	<section class="level1">
	<p>Results suggest that large displays facilitate tasks with multiple windows and rich information 
	because they offer a more immersive experience, with enhanced peripheral awareness</p>
	</section>
	
	<section class="level1">
	<p>Larger displays promote physical navigation and improve user performance for search, navigation 
	and pattern-finding tasks</p>
	</section>
	
	
<aside class="notes">
large data-set, virtual navigation, more immersive experience, promote physical navigation
</aside>
</section>

<section class="level1">
<p>Even so, physical locomotion is more time-consuming and tiring than virtual navigation, and 
manipulating data with well-known devices and widgets may be more efficient</p>
</section>

<section class="slide level1">
<p>Variables</p>
<aside class="notes">
•	Control the complexity of our classification task via several parameters: number of items, number of classes, number of containers, and representation of the item (including the label font size)
•	We control the difficulty by setting the number of classes (Easy or Hard)
•	Use three levels for labelsize factor (small, medium, and large)
•	On the desktop, participants can pan and zoom the scene in order to read the labels, find the target container, and identify which item to move.
•	On the wall-size display, users stand or walk in front of the wall and use a tablet to control the cursor.

</aside>
</section>

<section class="slide level1">
<p>Reasons for choosing the variables</p>
<aside class="notes">
</aside>
</section>

<section class="slide level1">
<p>Exp 1:</p>
<aside class="notes">
Goal is to investigate the trade-offs between physical and virtual navigation and how they affect task performance
</aside>
</section>

<section class="slide level1">
<p>Three hypothesis:</p>
	<section class="level1">
	<p>Wall performs better than Desktop for smaller labels</p>
	</section>
	
	<section class="level1">
	<p>Wall performs better than Desktop for harder tasks</p>
	</section>
	
	<section class="level1">
	<p>Desktop performs better than Wall for larger labels and simpler tasks</p>
	</section>
</section>

<section class="slide level1">
<p>Exp 2:</p>
<aside class="notes">
Compared three destop techniques in a second expirement: the baseline pan-and-zoom technique, an overview+detail 
technique and a focus+context technique
</aside>
</section>

<section class="slide level1">
<p>Analysis</p>
<aside class="notes">
Participants filled out a questionaniare about their subjective workload at the end of each display condition 
and another about their preferences at the end
</aside>
</section>

<section class="slide level1">
<p>[2x3x2] within-participants design with three factors: (display, labelsize, and difficulty)</p>
</section>

<section class="slide level1">
<p>Results:</p>
	<section class="level1">
	<p>For large labels, Desktop is faster than Wall for both Easy and Hard difficulty</p>
	</section>
	
	<section class="level1">
	<p>For Medium labels there is no significant difference for Easy, but Wall is faster than Desktop for Hard</p>
	</section>
	
	<section class="level1">
	<p>For Small labels, Wall is faster than Desktop for both Easy and Hard</p>
	</section>
</section>

<p>Ultimately</p>
<aside class="notes">
•	As predicted, the desktop is faster for Large labels and the Wall is faster for Small labels
•	However, the magnitude of the difference depends on the difficulty
•	The absolute difference between Wall and Desktop in the Small-Hard condition is large, with the wall being about 35% faster
•	This supports the hypothesis that complex tasks become intractable on the desktop but still manageable on the wall-size display
•	EXP 2: The analysis of variance revealed no significant effect of technique on task completion time
</aside>
</section>

<section class="slide level1">
<p>Practical Implications</p>
<aside class="notes">
•	In summary though, the experiment confirmed that the wall-size display out performs the desktop for difficult data classification 
tasks
</aside>
</section>
		
<section class="slide level1">
<p>The in-car interface</p>
<aside class="notes">
What makes a good in-car interface? We are currently seeing a shift from a more traditional button and knob dashboard to one that is 
completely accessed/controlled through a touch screen.
</aside>
</section>	

<section class="slide level1">
<p>Affordances</p>
<aside class="notes">
While buttons and knobs may seem old-school and out-of-date, they do allow for important affordances that current touch screens 
cannot. For example, once a user is accustomed to the buttons, they are able to associate the way a certian button, lets say the volume 
knob for example, feels and therefore I/O may be done with little to no distraction to the driver. If a driver knows how the 
volume knob feels then they are able to change the volume without even looking away from the road.
</aside>
</section>

<section class="slide level1">
<a href="#">
	<img src="http://www.proclipusa.com/images/image.aspx/media/images/products/dashmounts/854352-4.JPG-800x">
</a>
<aside class="notes">
So here is my car actually, and we can see the volume button is of a different size than the other buttons in addition 
to being a different texture
</aside>
</section>

<section class="slide level1">
<p>Distraction</p>
<aside class="notes">
And as we know from kujala & Salvucci paper, anything distraction more than two seconds is dangerous
</aside>
</section>

<section class="slide level1">
<a href="#">
	<img src="http://blog.scottlogic.com/wloveland/assets/car-uis/tesla.jpg" 
	alt="Ref image" style="width:80%;height:80%;">
</a>
<aside class="notes">
Example of an in-car interface
</aside>
</section>

<section class="slide level1">
<a href="#">
	<img src="https://static-secure.guim.co.uk/sys-images/Observer/Pix/pictures/2015/1/5/1420473362163/Apples-CarPlay-012.jpg">
</a>
<aside class="notes">
Here you can see the interface acts much like traditional touch screen interfaces that we are familiar with such as an ipad 
or even more so, your phone. This is a good thing because it takes advantage of a design that we are both comfortable with 
and used to. However, this interface requires a large amount of attention and as (paper read for class about 2 second rule 
for driving) shows, looking away for any more than two seconds can be potentially dangerous/fatal. So how might we take advantage 
of such touch screens and gestures for in-car interfaces?
</aside>
</section>

<section class="slide level1">
<p>Proposal</p>
<aside class="notes">
So here is a proposal for the stated problem
</aside>
</section>

<section class="slide level1">
<aside class="notes">
So here is a proposal for the stated problem
</aside>
</section>	

<section data-background-iframe="https://www.youtube.com/embed/XVbuk3jizGM?start=20&end=122&version=3&modestBranding=1&autoplay=1&rel=0&amp;showinfo=0">
<aside class="notes">
Showing the video with the proposed UX solution
</aside>
</section>	

<section class="slide level1">
<p>Important concepts from video</p>
<aside class="notes">
So from the video we see an interface that has the ability to be used without much distraction to the user. The user can perform 
different operations simply by changing the number of fingers they use to interact with touch surface. Another important aspect is 
the forgivingness of the interface as it allows people to perform the same function by touching anywhere on the screen instead of 
standard point.
</aside>
</section>

<section class="slide level1">
<h3>Drivers tend to use only four of the UI features:</h3>
	
	<section class="slide level1">
	<p></p>
	</section>
	<!--possibly add some pics in place of listing the words-->
	<section class="slide level1">
	<a href="#">
		<img src="http://s3.motoringfile.com.s3.amazonaws.com/wp-content/uploads/2014/05/apple-carplay-phone-call.png" 
		alt="Ref image" style="width:80%;height:300px;">
	</a>
	<aside class="notes">
	phone calls
	</aside>
	</section>
	
	<section class="slide level1">
	<a href="#">
		<img src="https://s-media-cache-ak0.pinimg.com/736x/f1/3a/0e/f13a0e659a0f95203ba9f6de89fa08b4.jpg" 
		alt="Ref image" style="width:80%;height:300px;">
	</a>
	<aside class="notes">
	music
	</aside>
	</section>
	
	<section class="slide level1">
	<a href="#">
		<img src="http://i.imgur.com/FHxAnpj.png" 
		alt="Ref image" style="width:80%;height:300px;">
	</a>
	<aside class="notes">
	navigation
	</aside>
	</section>
	
	<section class="slide level1">
	<a href="#">
		<img src="http://www.automonster.ca/wp-content/uploads/2010/12/rear-view-car-camera.jpg" 
		alt="Ref image" style="width:80%;height:300px;">
	</a>
	<aside class="notes">
	rear-view camera
	</aside>
	</section>
	
<aside class="notes">
According to www.hugeinc.com, they did a study and found that drivers tend to only use four UI features, while the others go widely unutilized.
</aside>
</section>

<section class="slide level1">
<p>From this..</p>
<aside class="notes">
From this we can glean that creating an interface where many options are available such as the typical ios interface is not necessary 
for in-car interfaces as drivers only use a couple of functions. Therefore, the proposed solution seen in the video would work great 
due to the fact that it only allows for a few functionality options due to the physical gesture limitations.
</aside>
</section>

<section class="slide level1">
<p>My suggestions</p>
<aside class="notes">
My suggestion would be either buttons or a touch screen interface such as the one we saw in a video that allow for affordances such as 
touch memory and/or gestures such as using different fingers for different functions as exemplified in the video. This will ultimately 
allow for a "hands-free" interface system where drivers do not have to avert their eyes from the road thus resulting in less distraction 
and hopefully less accidents
</aside>
</section>

<section class="slide level1">
<p>Works Cited</p>
<p>[1] www.hugeinc.com/ideas/perspective/riding-in-cars-with-uis</p>
<p>[2] https://www.youtube.com/watch?v=XVbuk3jizGM&list=LLunkFs4TPXfpIO88z8zLUBw&index=1</p>
<p>[3] Modeling Visual Sampling on In-Car Displays: The Challenge of Predicting Safety-Critical Lapses of Control</p>
<aside class="notes">
</aside>
</section>

<section class="slide level1">
<p>Questions?</p>
<aside class="notes">
</aside>
</section>



			</div>

		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>

		<script>

			// Full list of configuration options available at:
			// https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				controls: true,
				progress: true,
				history: true,
				center: true,
				overview: true,
				touch: true,
			

				transition: 'slide', // none/fade/slide/convex/concave/zoom
				
				// USE THESE SETTINGS FOR THE AUDIO AND AUTO-ADVANCE
				//autoSlide: 5000,
				audioPrefix: 'audio/',        // audio files are stored in the "audio" folder
				audioSuffix: '.ogg',	      // audio files have the ".ogg" ending
				audioDefaultDuration: 2, // default duration if no audio is available
				audioPlayerOpacity: 0.05,     // opacity value of audio player if unfocused
				audioTextToSpeechURL: "http://tts-api.com/tts.mp3?q=",  // text is added to this URL
				
				// Optional reveal.js plugins
				dependencies: [
					{ src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
					{ src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/highlight/highlight.js', async: true, condition: function() { return !!document.querySelector( 'pre code' ); }, callback: function() { hljs.initHighlightingOnLoad(); } },
					{ src: 'plugin/zoom-js/zoom.js', async: true },
					{ src: 'plugin/notes/notes.js', async: true },
					{ src: 'plugin/audio-slideshow/audio-slideshow.js', condition: function( ) { return !!document.body.classList; } }
				]
			});
		</script>

	</body>
</html>
				
