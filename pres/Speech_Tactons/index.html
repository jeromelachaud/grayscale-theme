<!doctype html>
<html lang="en">

	<head>
		<meta charset="utf-8">
		
		<!-- BASE URL: change this href to the intended URL of your slide show, e.g. - http://USERNAME.github.io/SLIDESHOW-REPO/ -->
		<base href="http://millsjb.github.io/inls161-revealjs-template//"> 

		<title>Speech Tactons</title>
		
		
		<meta name="author" content="Josh Mills">
		
		<meta name="apple-mobile-web-app-capable" content="yes" />
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
		
		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/night.css" id="theme">
		<!-- Code syntax highlighting -->
  		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>

		<!--[if lt IE 9]>
		<script src="lib/js/html5shiv.js"></script>
		<![endif]-->
	</head>

	<body>
		
		<div class="reveal">

			<!-- Any section element inside of this container is displayed as a slide -->
			<div class="slides">
				
				<section>
					<h2>Speech Tactons Improve Speech Warnings for Drivers</h2>
					<p>Josh Mills</p>
					<p>
						<h4>2016-02-25</h4>
					</p>
				</section>

<section class="slide level1">
<p>Common Themes/What I took away from this..</p>
<aside class="notes">
Multi-modality is king, and perceived annoyance is actually a positive, but only when considering Lh scenarios
</aside>
</section>

<section class="slide level1">
<p>Focus of this study</p>
<aside class="notes">
This study evaluated a set of speech and tactile warnings, looking primarily at multi-modal warnings that combined both Speech warnings and Tactile warnings (Speech Tactons)
</aside>
</section>

<section class="slide level1">
<p>What are speech tactons?</p>
	<section class="slide level1">
	</section>
	
	<section class="slide level1">
	<p>They retain the rhythm of speech and used different levels of roughness and intensity to convey urgency</p>
	</section>
	
	<section class="slide level1">
	<a href="#">
		<img src="http://millsjb.github.io/pres/Speech_Tactons/Speech_tacton_ex.png" 
		alt="Ref image" style="width:80%;height:550px;">
	</a>
	</section>
</section>	

<aside class="notes">
This study evaluated a set of speech and tactile warnings, looking primarily at multi-modal warnings that combined both Speech warnings and Tactile warnings (Speech Tactons)
</aside>
</section>

<section class="slide level1">
<p>How is speech perceived in warnings in terms of its urgency, annoyance, and alerting effectiveness?</p>
	<section class="slide level1">
	</section>
	
	<section class="slide level1">
	<p>“Danger”</p>
	</section>
	
	<section class="slide level1">
	<p>“Warning”</p>
	</section>
	
	<section class="slide level1">
	<p>“Caution”</p>
	</section>
	
	<section class="slide level1">
	<p>“Notice”</p>
	</section>
	
	<section class="slide level1">
	<p>Speaking signal words urgently</p>
	</section>
<aside class="notes">
They found that the signal word “Danger” was perceived as more urgent compared to the words “Warning” and “Caution”, 
which in turn were perceived as more urgent compared to “Notice”. Also, Signal words spoken urgently created higher
 ratings compared to non-urgently, which in turn were higher compared to words spoken in a monotone manner
</aside>
</section>

<section class="slide level1">
<p>How to increase richness in tactile cues/warnings?</p>
<section class="slide level1">
	</section>
	
	<section class="slide level1">
	<p>Vary parameters such as rhythm, roughness and intensity</p>
	</section>
<aside class="notes">
Varying parameters such as rhythm and roughness (amplitude modulation on the original waveform that provides the vibration) 
of such messages enabled the design of richer cues without cost in their recognition accuracy, as long as a reduced number 
of different levels for roughness was used.
</aside>
</section>

<section class="slide level1">
<p>In this study..</p>
<aside class="notes">
In this study, tactile cues are used along with audio, varying the rhythm of the cues, by imitating the rhythm of speech
</aside>
</section>

<section class="slide level1">
<a href="#">
	<img src="http://millsjb.github.io/pres/Speech_Tactons/Speech_tacton_ex.png" alt="Ref image" style="width:80%;height:550px;">
</a>
<aside class="notes">
exemplified here
</aside>
</section>

<section class="slide level1">
<p>Three urgency levels:</p>
	<section class="slide level1">
	</section>
	
	<section class="slide level1">
	<p>Level High (LH)</p>
	</section>
	
	<section class="slide level1">
	<p>Level Medium (LM)</p>
	</section>
	
	<section class="slide level1">
	<p>Level Low (LL)</p>
	</section>
<aside class="notes">
The words “Danger!”, “Warning!”, “Notice!” were added before each Lh, Lm and Ll. the ac- tor was instructed 
to speak messages of LH in an urgent manner, as if a loved one was in imminent danger. Accord- ingly, LM messages 
were spoken non-urgently, as if in a friendly conversation with nothing interesting about the situation and LL messages 
were spoken in a monotone, deadpan manner 
</aside>

<section class="slide level1">
<p>Experiment 1</p>
<aside class="notes">
The first experiment investigated the subjective responses provided by participants when exposed to the warnings.
</aside>
</section>

<section class="slide level1">
<p>A 6×3×4 within subjects design was used with Message, Modality and Design as the independent variables and Perceived Urgency (PU), Perceived Annoy- ance (PA) and Perceived Alerting Effectiveness (PAE) as the dependent ones</p>
<aside class="notes">
A 6×3×4 within subjects design was used with Message, Modality and Design as the independent variables and Perceived Urgency (PU), Perceived Annoy- ance (PA) and Perceived Alerting Effectiveness (PAE) as the dependent ones
</aside>
</section>

<section class="slide level1">
<p>Set-up</p>
<aside class="notes">
participants were exposed to the 54 cues (6 A, 24 T, 24 AT) in a random order, to familiarize them with the signals. Afterwards, they were again presented with the cues and asked to rate them all in terms of PA, PU and PAE, by 
completing a 5-point Likert scale for each rating
</aside>
</section>

<section class="slide level1">
<p>Results</p>
	<section class="slide level1">
	</section>
	
	<section class="slide level1">
	<a href="#">
		<img src="http://millsjb.github.io/pres/Speech_Tactons/A.png" 
		alt="Ref image" style="width:80%;height:550px;">
	</a>
	</section>
	
	<section class="slide level1">
	<a href="#">
		<img src="http://millsjb.github.io/pres/Speech_Tactons/B.png" 
		alt="Ref image" style="width:80%;height:550px;">
	</a>
	</section>
	
	<section class="slide level1">
	<a href="#">
		<img src="http://millsjb.github.io/pres/Speech_Tactons/C.png" 
		alt="Ref image" style="width:80%;height:550px;">
	</a>
	</section>
<aside class="notes">
Contrasts revealed that the significant differences in ratings of PU described above were not present in modality T
</aside>
</section>


<section class="slide level1">
<p>Experiment 2</p>
<aside class="notes">
Experiment 2 investigated the recognition accuracy of participants when exposed to the T warnings
</aside>
</section>





















<section class="slide level1">
<p>Measures</p>
	<section class="slide level1">
	</section>
	
	<section class="slide level1">
	<p>Modality</p>
	</section>
	
	<section class="slide level1">
	<p>LDU</p>
	</section>
	
	<section class="slide level1">
	<p>Information (Abstract, language-based)</p>
	</section>
<aside class="notes">
An advantage of abstract warnings and warnings including visuals in the recognition task was observed.
</aside>
</section>

<section class="slide level1">
<p>Guidelines</p>
	<section class="slide level1">
	</section>
	
	<section class="slide level1">
	<a href="#">
		<img src="http://millsjb.github.io/pres/To_beep/guid.png" 
		alt="Ref image" style="width:80%;height:550px;">
	</a>
	</section>
<aside class="notes">
</aside>
</section>

<section class="slide level1">
<p>Experiment 1</p>
<aside class="notes">
recognition task, where the cues urgency was indentified with no critical event present
</aside>
</section>

<section class="slide level1">
<p>Issues</p>
<aside class="notes">
One of the issues that I had with this experiment is based on the fact that they did not have a true control 
variable where the subjects experienced the dangerous situations without warnings. Another issue I had had to 
do with how the subjects reacted to the warnings. I do not feel that pressing a certain button on the steering 
wheel is an accurate measure of reaction/response time. I think that the subjects should have reacted as if they 
were in a real car, by slamming on the breaks or swerving the steering wheel.
</aside>
</section>

</section>
<section class="slide level1">
<p>Results</p>
	<section class="slide level1">
	</section>
	
	<section class="slide level1">
	<a href="#">
		<img src="http://millsjb.github.io/pres/To_beep/results.png" 
		alt="Ref image" style="width:80%;height:550px;">
	</a>
	</section>
<aside class="notes">
An advantage of abstract warnings and warnings including visuals in the recognition task was observed.
</aside>
</section>

<section class="slide level1">
<p>Experiment 2</p>
<aside class="notes">
response task where responses to high urgency warnings were measured in the presence of such an event
</aside>
</section>

<section class="slide level1">
<p>Independent variables:</p>
	<section class="slide level1">
	</section>
	
	<section class="slide level1">
	<p>Modality</p>
	</section>
	
	<section class="slide level1">
	<p>LDU</p>
	</section>
	
	<section class="slide level1">
	<p>Information</p>
	</section>
	
	<section class="slide level1">
	<p>Time</p>
	</section>
	
<aside class="notes">

</aside>
</section>

<section class="slide level1">
<p>Dependent variables:</p>
	<section class="slide level1">
	</section>
	
	<section class="slide level1">
	<p>Response Time</p>
	</section>
	
	<section class="slide level1">
	<p>Lateral Deviation</p>
	</section>
	
	<section class="slide level1">
	<p>Steering Angle</p>
	</section>
<aside class="notes">

</aside>
</section>

<section class="slide level1">
<p>Issues</p>
<aside class="notes">
Another issue that I had with this study was the fact that it was conducted as a simulated driving task. While helpful 
for testing, I question whether the results could be directly applied to a real-life situation where a user might actually 
not be paying attention and therefore need a warning whether in the form of a voice or vibrations.
</aside>
</section>

</section>
<section class="slide level1">
<p>Results</p>
	<section class="slide level1">
	</section>
	
	<section class="slide level1">
	<a href="#">
		<img src="http://millsjb.github.io/pres/To_beep/a.png" 
		alt="Ref image" style="width:80%;height:60%;">
	</a>
	</section>
	
	<section class="slide level1">
	<a href="#">
		<img src="http://millsjb.github.io/pres/To_beep/b.png" 
		alt="Ref image" style="width:80%;height:60%;">
	</a>
	</section>
	
	<section class="slide level1">
	<a href="#">
		<img src="http://millsjb.github.io/pres/To_beep/c.png" 
		alt="Ref image" style="width:80%;height:60%;">
	</a>
	</section>
	
<aside class="notes">
Overall, cues including audio performed better in the response task, but multimodal cues were the best performing. Driving 
behaviour was marginally better when using language-based cues compared to the abstract ones. Although, the results show the 
benefit of using abstract cues in non-critical situations and a possible advantage of language-based cues in a critical situation.
</aside>
</section>



</section>
<section class="slide level1">
<p>Take-aways from both experiments</p>
<aside class="notes">
Mulitmodal seemed to have the best performance, although unimodal visuals for recognition and unimodal audio for response were an exception. 
I think that it is safe to say, in order to optimize response and reaction performance, multimodal cues are best unless vision or audio is concerned.
</aside>
</section>


<section class="slide level1">
<p>Real-world Application</p>
	
	<section class="slide level1">
	</section>
	
	<section class="slide level1">
	<a href="#">
		<img src="http://dzag5wgsqu6mr.cloudfront.net/wp-content/uploads/2014/06/Driver-Monitoring-System.jpg" 
		alt="Ref image" style="width:80%;height:80%;">
	</a>
	</section>
	
	<section class="slide level1">
	<a href="#">
		<img src="http://www.smartmotorist.com/images/motorist_news/blind-spot-warning-systems.jpg" 
		alt="Ref image" style="width:80%;height:80%;">
	</a>
	</section>
	
	<section class="slide level1">
	<a href="#">
		<img src="http://blogmedia.dealerfire.com/wp-content/uploads/sites/344/2015/11/small-braking-assist-400.jpg" 
		alt="Ref image" style="width:80%;height:60%;">
	</a>
	</section>
	
	
<aside class="notes">
The derived guidelines can aid car warning designers and extend available knowledge by directly com- paring these different 
ways of informing drivers.
</aside>
</section>

<section class="slide level1">
<p>Questions?</p>
<aside class="notes">
</aside>
</section>




			</div>

		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>

		<script>

			// Full list of configuration options available at:
			// https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				controls: true,
				progress: true,
				history: true,
				center: true,
				overview: true,
				touch: true,
			

				transition: 'slide', // none/fade/slide/convex/concave/zoom
				
				// USE THESE SETTINGS FOR THE AUDIO AND AUTO-ADVANCE
				//autoSlide: 5000,
				audioPrefix: 'audio/',        // audio files are stored in the "audio" folder
				audioSuffix: '.ogg',	      // audio files have the ".ogg" ending
				audioDefaultDuration: 2, // default duration if no audio is available
				audioPlayerOpacity: 0.05,     // opacity value of audio player if unfocused
				audioTextToSpeechURL: "http://tts-api.com/tts.mp3?q=",  // text is added to this URL
				
				// Optional reveal.js plugins
				dependencies: [
					{ src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
					{ src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/highlight/highlight.js', async: true, condition: function() { return !!document.querySelector( 'pre code' ); }, callback: function() { hljs.initHighlightingOnLoad(); } },
					{ src: 'plugin/zoom-js/zoom.js', async: true },
					{ src: 'plugin/notes/notes.js', async: true },
					{ src: 'plugin/audio-slideshow/audio-slideshow.js', condition: function( ) { return !!document.body.classList; } }
				]
			});
		</script>

	</body>
</html>